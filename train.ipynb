{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f3eb97-41a4-4732-9c7b-5d457aabfc07",
   "metadata": {},
   "source": [
    "### Import All mandatory Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fb8df79-6dd2-43e8-8323-1d3dc9c4595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a27e2fc1-2ff2-4d7d-a106-40f71ec51a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9785bd4e-f1b3-4545-8bba-a0a92de25462",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffdd65b-747e-497a-8988-aab3cc846c3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/sentiment_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m em1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(df1)\n\u001b[0;32m      3\u001b[0m em1\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# df1 = 'data/sentiment_analysis.csv'\n",
    "# em1 = pd.read_csv(df1)\n",
    "# em1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b638f30-3b58-4d44-af3b-2f8e1f9bba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = 'data/test.csv'\n",
    "# em2 = pd.read_csv(df2, encoding='unicode_escape')\n",
    "# em2 = em2[(em2['sentiment']=='positive') | (em2['sentiment']=='neutral') | (em2['sentiment']=='negative')]\n",
    "# em2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d379680b-138b-4268-8aef-eebfc5c96f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2118, 2)\n",
      "(2118, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# File path for the existing dataset\n",
    "input_file1 = 'data/sentimental_data.csv'\n",
    "\n",
    "# Read data from CSV file\n",
    "em1 = pd.read_csv(input_file1)\n",
    "\n",
    "# Select relevant columns\n",
    "# em1 = em1[['text', 'sentiment']]\n",
    "em1 = em1[(em1['sentiment']=='positive') | (em1['sentiment']=='neutral') | (em1['sentiment']=='negative')]\n",
    "# Display the dataset\n",
    "print(em1.shape)  # Display the first few rows of em1\n",
    "print(em2.shape)  # Display the first few rows of em1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe25e55-e1b5-4a88-91bf-9723d3ce7e69",
   "metadata": {},
   "source": [
    "#### Concatination of 2 Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80df1aa6-6528-4f58-b757-4827f5e6d6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2118, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em1 = em1[['text','sentiment']]\n",
    "# em2 = em2[['text','sentiment']]\n",
    "# final_data = pd.concat([em1,em2],axis=0)\n",
    "final_data = em1\n",
    "final_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87da4743-e351-4452-8436-4b6c32632ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am not happy</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love the new design of the website!</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The weather is nice today.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm really disappointed with the service.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The movie was fantastic, I enjoyed every momen...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  label\n",
       "0                                     I am not happy  negative    0.0\n",
       "1              I love the new design of the website!  positive    2.0\n",
       "2                         The weather is nice today.   neutral    1.0\n",
       "3          I'm really disappointed with the service.  negative    0.0\n",
       "4  The movie was fantastic, I enjoyed every momen...  positive    2.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ----------- This Shell is Experimetal can not harm the model if mistakenly run only this is for elaboration --------------\n",
    "# Mapping of positive negative and neutral\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "# Apply the mapping to create a new 'label' column\n",
    "final_data['label'] = final_data['sentiment'].map(sentiment_to_label)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dee3a7f5-e08c-430e-aa95-c62821cd041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2118, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We Only Have to work With text and its sentiment we can also go with it's label as well only some will change in the code\n",
    "\n",
    "data = final_data[['text','sentiment']]\n",
    "# for Experiment\n",
    "# data = emotions[['text','label']]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80b1dc-214a-412c-8828-41a45f94af67",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a325f61b-02d2-4a43-9854-7bc070b2c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    use_idf=True,\n",
    "    norm='l2',\n",
    "    smooth_idf=True\n",
    ")\n",
    "# y= data.label.values\n",
    "y = data.sentiment.values\n",
    "X = tfidf.fit_transform(data['text'].values.astype('U'))\n",
    "tfidf_vectorizer = open('tfidf_vectorizer.sav','wb')\n",
    "pickle.dump(tfidf,tfidf_vectorizer)\n",
    "tfidf_vectorizer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2477bfd6-f1ff-4323-9c56-9dfd029c7558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset into a pandas DataFrame\n",
    "# data = pd.read_csv('data/sentimental_data.csv')\n",
    "\n",
    "# # Initialize TF-IDF Vectorizer\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     use_idf=True,\n",
    "#     norm='l2',\n",
    "#     smooth_idf=True\n",
    "# )\n",
    "\n",
    "# # Fit and transform TF-IDF on the text data\n",
    "# X = tfidf.fit_transform(data['text'].values.astype('U'))  # Convert to Unicode strings\n",
    "# y = data['sentiment'].values  # Assuming 'sentiment' is the column name for labels\n",
    "\n",
    "# # Save the TF-IDF vectorizer using pickle\n",
    "# with open('tfidf_vectorizer.sav', 'wb') as file:\n",
    "#     pickle.dump(tfidf, file)\n",
    "\n",
    "# print(\"TF-IDF vectorizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96277c-9f8b-47d4-a913-6ef5fcb3b427",
   "metadata": {},
   "source": [
    "### Prepare data for Traning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "064bede2-7cf8-4ec0-899f-185ee4064996",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68d5fa-b9b9-4734-9204-e5f0e5d324af",
   "metadata": {},
   "source": [
    "### Model Traning and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fccb9c8e-5e1f-4f6c-8101-f5dce2448491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.9s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    "    max_iter=300\n",
    ").fit(X_train,y_train)\n",
    "saved_model = open('saved_model.sav','wb')\n",
    "pickle.dump(clf,saved_model)\n",
    "saved_model.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f17bf-1e96-4ab5-9f1b-5db39ef5f5b1",
   "metadata": {},
   "source": [
    "### Check Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cff9ddaf-d6b8-47f8-b050-3a1cf5cb80c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy is : 100.00%\n"
     ]
    }
   ],
   "source": [
    "filename = 'saved_model.sav'\n",
    "with open(filename, 'rb') as model_file:\n",
    "    saved_model = pickle.load(model_file)\n",
    "accuracy = saved_model.score(X_test,y_test)\n",
    "print(f\"Model Accuracy is : {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c639eb-ef8c-4383-a508-6cf074b1d861",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16cb07-612d-4a01-abad-e3ff49d2dc49",
   "metadata": {},
   "source": [
    "##### You Can Directly run Prediction shell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0267fa9f-a537-4e68-ba03-ce1f85961132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter you Text to Predict the Sentiment : you are not good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Text Sentiment is : negative\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'saved_model.sav'\n",
    "with open(filename, 'rb') as model_file:\n",
    "    saved_model = pickle.load(model_file)\n",
    "    \n",
    "vectorizer_filename = 'tfidf_vectorizer.sav'\n",
    "with open(vectorizer_filename, 'rb') as vectorizer_file:\n",
    "    tfidf_vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "text = input(\"Enter you Text to Predict the Sentiment :\")\n",
    "text_tfidf = tfidf_vectorizer.transform([text])\n",
    "prediction = saved_model.predict(text_tfidf)\n",
    "print(f\"Your Text Sentiment is : {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc40a2-1b03-48e2-b88a-63f799daae65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
